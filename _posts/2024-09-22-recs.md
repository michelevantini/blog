---
title: "Recommenders and personalization"
permalink: /recs
date: 2024-09-22
---

It appears to me that the literature about recommenders and personalization is essentially split into these categories:
 1. More theoretical results: typically proofs of convergence of some method and then tested on some benchmark dataset (for example, [this](https://www.uber.com/en-FI/blog/engineering/data/?uclick_id=268bf0e4-47d9-4154-b2a6-dc5f2e736e82))
 2. Real-world tests with existing or new methods: company X implements method Y and shows how much that improves target metrics compared to some basiline. Occasionally, the company will also show some new metrics or proxy metrics (see for example are the corpus-related metrics presented by DeepMind and experimented on YouTube Shorts [here](https://arxiv.org/html/2305.07764v2))
 3. Engineering-related aspects of recommenders: data engineering and practical machine learning engineering consideration to run recommenders more in real-time at scale (a good example is the [TikTok recommender paper](https://arxiv.org/pdf/2209.07663))
 4. A mix of the above

Assuming you are a data scientist or ML engineer, I believe one should be interested in all of them, with probably a focus on 2,3 and 4. 
Through this article we will focus mostly on practical aspects of recommender systems and methods.

## Methods
Recommender systems are typically categorised according to the following taxonomy:
 - Content based methods: given some features for users and items, define a model on user-item interactions
 - Collaborative filtering methods: just define a model on user-item interactions and user/item representations have to be learned
 - Hybrid methods
You can find a quick overview of Content based methods and collaborative filtering methods [here](https://developers.google.com/machine-learning/recommendation/overview/candidate-generation)

### Collaborative filtering
A fearly simple to implement yet effective baseline is the Collaborative filtering approach, where we learn user/item representations from an interaction matrix. The learned representations can then be used to make predictions and they follow the basic idea "users that liked this also liked this". Most commonly used Collaborative filtering methods include:
 - Matrix factorization
 - Neural Collaborative Filtering
 - Factorization Machines: which are mostly considered Collaborative filtering methods since they model a user-item interaction matrix. But they can handle user and item features, so they are also a Content based method 

### Reinforcement-learning approaches
The basic idea of using Reinforcement-Learning (RL) in recommenders is to have an agent (our recommender) that tries to take actions (make recommendations) in an environment (our platform/website) where our users exist, with the goal of optimizing a specific metric. One benefit of this approach, is that compared to a Collaborative filtering method where we probably need some differentiable target to optimize, in RL-based methods we can sometimes directly optimize business metrics or proxy metrics.

We can further split these approaches into sub-categories:
 - Bandits approaches
 - Deep RL methods
 - Hybrid methods 

While Deep RL methods are an [active field or research](https://scitator.medium.com/rl-in-recsys-an-overview-e02815019a8f) and they did show positive results on real-world large scale personalization scenarios, it seems that the most commonly used methods are Collaborative filtering, Factorization machines and Bandits algorithms.

List of resources:
 - [Netflix blog](https://netflixtechblog.com/)
 - [Spotify blog](https://engineering.atspotify.com/)
 - [Uber blog](https://www.uber.com/en-FI/blog/engineering/data/?uclick_id=268bf0e4-47d9-4154-b2a6-dc5f2e736e82)
